{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"data-preparation.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyO4GUHftfWUo3XWB1we4Tz5"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"pzImNeOjy4jZ"},"source":["# import libraries\n","import pandas as pd\n","import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_RbelOPK4TFB"},"source":["# data preparation\n","---------------------\n","The data preparation phase covers all activities to construct the final dataset (data that will be fed into the modeling tool(s)) from the initial raw data. Data preparation tasks are likely to be performed multiple times and not in any prescribed order. Tasks include table, record and attribute selection as well as transformation and cleaning of data for modeling tools."]},{"cell_type":"markdown","metadata":{"id":"Wfrdzmhe0Zfr"},"source":["## select data\n","----------\n","\n","### task\n","\n","Decide on the data to be used for analysis. Criteria include relevance to the data mining goals, quality and technical constraints such as limits on data volume or data types. Note that data selection covers selection of attributes (columns) as well as selection of records (rows) in a table.\n","\n","### output\n","\n","List the data to be included/excluded and the reasons for these decisions."]},{"cell_type":"markdown","metadata":{"id":"XmON6H8NWy4G"},"source":["#### select data source\n","\n","| # | data | included/excluded | reasons | quality | volume/data types |\n","|:---:|:---|:---|:---|:---|:---|\n","| 1 |  | included |  |  |  |\n","\n","#### select attributes & records\n","\n"]},{"cell_type":"markdown","metadata":{"id":"MTt2pAHhr8Od"},"source":["## clean data\n","------------------\n","\n","### task\n","\n","Raise the data quality to the level required by the selected analysistechniques. This may involve selection of clean subsets of the data, the insertion of suitable defaults or more ambitious techniques such as the estimation of missing data by modeling.\n","\n","### output\n","\n","Describe what decisions and actions were taken to address the data quality problems reported during the verify data quality task of the data understanding phase. Transformations of the data for cleaning purposes and the possible impact on the analysis results should be considered.\n"]},{"cell_type":"code","metadata":{"id":"CXvyZaSTZP0h"},"source":["# remove unnncesary columns\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WLLTAm40Y1mT"},"source":["# clean missing data\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"spUFSLcwZHN3"},"source":["# clean outlier\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SAEHAkLIsImG"},"source":["## construct data\n","----------\n","\n","### task\n","\n","This task includes constructive data preparation operations such as the production of derived attributes, entire new records or transformed values for existing attributes.\n","\n","### output\n","\n","#### derived attributes\n","\n","Derived attributes are new attributes that are constructed from one or more existing attributes in the same record. \n","\n","Examples: area = length * width\n","\n","#### generated records\n","\n","Describe the creation of completely new records. \n","\n","Example: create records for customers who made no purchase during the past year.There was no reason to have such records in the raw data, but for modeling purposes it might make sense to explicitly represent the fact that certain customers made zero purchases.\n"]},{"cell_type":"code","metadata":{"id":"_Ahz4A0_ZYlo"},"source":["# derive attributes\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AJ8ftwCUZaYJ"},"source":["# generate records\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NLwXOV0Tsgzi"},"source":["## integrate data\n","-------------\n","\n","### task\n","\n","These are methods whereby information is combined from multiple tables or records to create new records or values.\n","\n","### output\n","\n","Merging tables refers to joining together two or more tables that have different information about the same objects. \n","\n","Example: a retail chainhas one table with information about each store's general characteristics(e.g., floor space, type of mall), another table with summarized sales data (e.g., profit, percent change in sales from previous year) and another with information about the demographics of the surrounding area. Each of these tables contains one record for each store. These tables can be merged together into a new table with one record foreach store, combining fields from the source tables.\n","\n","Merged data also covers aggregations. Aggregation refers to operations where new values are computed by summarizing together information from multiple records and/or tables. For example, converting a table ofcustomer purchases where there is one record for each purchase into a new table where there is one record for each customer, with fields such as number of purchases, average purchase amount, percent of orders charged to credit card, percent of items under promotion, etc.\n"]},{"cell_type":"markdown","metadata":{"id":"RWIPJBums0C7"},"source":["# format data\n","----------------\n","\n","### task\n","\n","Formatting transformations refer to primarily syntactic modifications made to the data that do not change its meaning, but might be required by the modeling tool.\n","\n","### output\n","\n","Some tools have requirements on the order of the attributes, such as the first field being a unique identifier for each record or the last field being the outcome field the model is to predict.\n","\n","It might be important to change the order of the records in the dataset. Perhaps the modeling tool requires that the records be sorted according to the value of the outcome attribute. A common situation is that the records of the dataset are initially ordered in some way but the modeling algorithm needs them to be in a fairly random order. For example, when using neural networks it is generally best for the records to be presented in a random order although some tools handle this automatically with-out explicit user intervention.\n","\n","Additionally, there are purely syntactic changes made to satisfy the requirements of the specific modeling tool. \n","\n","Examples: removing commas from within text fields in comma-delimited data files, trimming all values to a maximum of 32 characters.\n"]},{"cell_type":"markdown","metadata":{"id":"-u6lu6ep4EgC"},"source":["## note/questions\n","-------------\n","\n","#### select data\n","\n","#### clean data\n","\n","#### construct data\n","\n","#### integrate data\n","\n","#### format data\n","\n"]},{"cell_type":"code","metadata":{"id":"77gTgxgz4PYQ"},"source":[""],"execution_count":null,"outputs":[]}]}