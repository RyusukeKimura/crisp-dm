{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pzImNeOjy4jZ"
   },
   "outputs": [],
   "source": [
    "# mount drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move directory\n",
    "import os\n",
    "colab_dir = \"./drive/MyDrive/\"\n",
    "os.chdir(colab_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib_inline\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import python module\n",
    "from python.xxxx import XXXX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seed\n",
    "import random\n",
    "random.seed(335)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# magic word\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for better viz\n",
    "import pprint\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reference\n",
    "-------------------\n",
    "\n",
    "- [pandas cheat sheet](https://github.com/pandas-dev/pandas/tree/master/doc/cheatsheet)\n",
    "- [numpy cheat sheet(data camp)](https://www.datacamp.com/community/blog/python-numpy-cheat-sheet)\n",
    "- [scikit-learn cheat sheet(data camp)](datacamp.com/community/blog/scikit-learn-cheat-sheet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_RbelOPK4TFB"
   },
   "source": [
    "# modeling\n",
    "---------------------\n",
    "In this phase, various modeling techniques are selected and applied and their parameters are calibrated to optimal values. Typically, there are several techniques for the same data mining problem type. Some techniques have specific requirements on the form of data. Therefore, stepping back to the data preparation phase is often necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wfrdzmhe0Zfr"
   },
   "source": [
    "## select modeling techuique\n",
    "----------\n",
    "\n",
    "### task\n",
    "\n",
    "As the first step in modeling, select the actual modeling technique that is to be used. Whereas you possibly already selected a tool in business understanding, this task refers to the specific modeling technique, e.g.,decision tree building with C4.5 or neural network generation with back propagation. If multiple techniques are applied, perform this task for each technique separately.\n",
    "\n",
    "### output\n",
    "\n",
    "#### modeling technique\n",
    "\n",
    "Document the actual modeling technique that is to be used.\n",
    "\n",
    "#### modeling assumptions\n",
    "\n",
    "Many modeling techniques make specific assumptions on the data, e.g.,all attributes have uniform distributions, no missing values allowed, class attribute must be symbolic etc. Record any such assumptions made."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MTt2pAHhr8Od"
   },
   "source": [
    "## generate test design\n",
    "------------------\n",
    "\n",
    "### task\n",
    "\n",
    "Before we actually build a model, we need to generate a procedure or mechanism to test the model's quality and validity. For example, in supervised data mining tasks such as classification, it is common to use error rates as quality measures for data mining models. Therefore, we typically separate the dataset into train and test set, build the model on the train set and estimate its quality on the separate test set.\n",
    "\n",
    "### output\n",
    "\n",
    "Describe the intended plan for training, testing and evaluating the models. A primary component of the plan is to decide how to divide the available dataset into training data, test data and validation datasets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SAEHAkLIsImG"
   },
   "source": [
    "## build model\n",
    "----------\n",
    "\n",
    "### task\n",
    "\n",
    "Run the modeling tool on the prepared dataset to create one or more models.\n",
    "\n",
    "### output\n",
    "\n",
    "#### parameter settings \n",
    "\n",
    "With any modeling tool, there are often a large number of parameters that can be adjusted. List the parameters and their chosen value, along with the rationale for the choice of parameter settings. \n",
    "\n",
    "#### models \n",
    "\n",
    "These are the actual models produced by the modeling tool, not a report.\n",
    "\n",
    "#### model description\n",
    "\n",
    "describe the resultant model. Report on the interpretation of the models and document any difficulties encountered with their meanings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "## closed test\n",
    "X_train, X_test, y_train, y_test = X, X, y, y\n",
    "\n",
    "## random split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### regression\n",
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### classification\n",
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### imbalanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imbalanced data: https://www.analyticsvidhya.com/blog/2020/07/10-techniques-to-deal-with-class-imbalance-in-machine-learning/\n",
    "## random under sampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "sampler = RandomUnderSampler()\n",
    "\n",
    "## random over sampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "sampler = RandomOverSampler()\n",
    "\n",
    "## SMOTE\n",
    "from imblearn.over_sampling import SMOTE\n",
    "sampler = SMOTE()\n",
    "\n",
    "## TomekLinks\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "sampler = TomekLinks()\n",
    "\n",
    "## NearMiss\n",
    "from imblearn.under_sampling import NearMiss\n",
    "sampler = NearMiss()\n",
    "\n",
    "## sampling\n",
    "X_train, y_train = sampler.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM\n",
    "from sklearn.svm import SVC\n",
    "model = SVC(kernel='linear', random_state=None)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBM\n",
    "!pip install optuna\n",
    "import optuna.integration.lightgbm as lgb\n",
    "lgb_train = lgb.Dataset(X_train, y_train)\n",
    "lgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train)\n",
    "params = {\n",
    "    \"objective\" : \"multiclass\",\n",
    "    \"metric\" : \"multi_logloss\",\n",
    "    \"num_class\" : len(y.unique())\n",
    "}\n",
    "model = lgb.train(params, lgb_train, valid_sets=lgb_eval)\n",
    "y_prob = model.predict(X_test, num_iteration=model.best_iteration)\n",
    "y_pred = np.argmax(y_prob, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NLwXOV0Tsgzi"
   },
   "source": [
    "## assess model\n",
    "-------------\n",
    "\n",
    "### task\n",
    "\n",
    "The data mining engineer interprets the models according to his domain knowledge, the data mining success criteria and the desired test design. This task interferes with the subsequent evaluation phase. Whereas the data mining engineer judges the success of the application of modeling and discovery techniques more technically, he contacts business analysts and domain experts later in order to discuss the data mining results in the business context. Moreover, this task only considers models whereas the evaluation phase also takes into account all other results that were produced in the course of the project. The data mining engineer tries to rank the models. He assesses the models according to the evaluation criteria. As far as possible he also takes into account business objectives and business success criteria. In most data mining projects, the data mining engineer applies a single technique more than once or generates data mining results with different alternative techniques. In this task, he also compares all results according to the evaluation criteria.\n",
    "\n",
    "### output\n",
    "\n",
    "#### model assessment\n",
    "\n",
    "Summarize results of this task, list qualities of generated models (e.g.,in terms of accuracy) and rank their quality in relation to each other. \n",
    "\n",
    "#### revised parameter settings\n",
    "\n",
    "According to the model assessment, revise parameter settings and tune them for the next run in the Build Model task. Iterate model building and assessment until you strongly believe that you found the best model(s). Document all such revisions and assessments.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### regression\n",
    "-----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### classification\n",
    "----------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(str('{:.1g}'.format(accuracy * 100)) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### binary classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### multi-class classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-u6lu6ep4EgC"
   },
   "source": [
    "## note/questions\n",
    "-------------\n",
    "\n",
    "#### select modeling technique\n",
    "\n",
    "#### generate test design\n",
    "\n",
    "#### build model\n",
    "\n",
    "#### assess model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "77gTgxgz4PYQ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMQn80GKbpYhOi2XJA3cST3",
   "collapsed_sections": [],
   "name": "modeling.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
